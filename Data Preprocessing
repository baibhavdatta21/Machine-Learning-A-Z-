#Machine Learning
#Data PreProcessing Template(Try to use all of these before creating any model)

#Importing Libraries

import numpy as np               #-------> #NUMpystands for numerical python, numpys are 50x faster than python lists, Numpy requires fast computation thus some of its code is written in C/C++ 
import matplotlib.pyplot as plt  #-------> #its mostly used for plotting graphs in ML
import pandas as pd              #-------> #best for importing datasets an managing datasets.


#import and manage data
#import a dataset
dataset=pd.read_csv('Data.csv')  #------->#importing our dataset
X=dataset.iloc[:,:-1].values     #------->#dividing our dataset(1)
Y=dataset.iloc[:,3].values       #------->#dividing our dataset(2)


#cleaning the data
from sklearn.impute import SimpleImputer   #-------->import the libraies
imp = SimpleImputer(missing_values=np.nan, strategy='mean')  #------>when we find there are missing values to solve it we may put the mean value in the column, median value..
imp=imp.fit(X[:,1:3])
X[:,1:3]=imp.transform(X[:,1:3])
from sklearn.preprocessing import OneHotEncoder        #-------->#if we are having say 3 values in a columns if try to just label encoder we will get the values in the form of 0,1,2 now pc will interpret that 2 has high priority but is not he case thus to avoid it we make new columns
from sklearn.compose import ColumnTransformer
columnTransformer = ColumnTransformer([('Country', OneHotEncoder(), [0])],remainder='passthrough')
X=np.array(columnTransformer.fit_transform(X))
from sklearn.preprocessing import LabelEncoder         #-------->here simple 0,1 works fine
l_e_y= LabelEncoder()
l_e_y.fit(Y)
Y=l_e_y.transform(Y) 



#splitting the dataset into trainning set and test set
from sklearn.model_selection import train_test_split    #------->this will be required in almost every algorithm
X_train,X_test ,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)



#Feature Sclicing
#euclidean distance
#If we don't do it one of our properties will get dominated by the other
from sklearn.preprocessing import StandardScaler       #-------->Getting each column values in between a certain range otherwise the ones having higher values will have higher priority (Rember the concept of eucleadian distance)
sc_X=StandardScaler()
X_train=sc_X.fit_transform(X_train)
X_test=sc_X.transform(X_test) 
